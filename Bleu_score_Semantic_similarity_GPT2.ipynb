{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "ref = \"OLIVER Charles, I thank thee for thy love to me, which 135 thou shalt find I will most kindly requite. I had myself notice of my brother’s purpose herein, and have by underhand means labored to dissuade him from it; but he is resolute. I’ll tell thee, Charles, it is the stubbornest young fellow of France, full of 140 ambition, an envious emulator of every man’s good parts, a secret and villainous contriver against me his natural brother. Therefore use thy discretion.\"\n",
        "gen = \"OLIVER Charles, I thank thee for thy love to me, And in this most unbashful of a passion, Wearing thy hearer in thy mistress’ praise, Thou seem’st so empty and unregarded That thou shouldst have better pleased me with this deed. So holy and so perfect is my love to thee, And I to thee I’ll show it. Now I will forget the pageant and\"\n",
        "\n",
        "#Calculate Bleu Score\n",
        "bleu_score = sentence_bleu([ref], gen)\n",
        "print(f\"Bleu Score: {bleu_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce_5hfULZUlE",
        "outputId": "7b72bdfe-97f8-468b-d962-edb6b3551208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bleu Score: 0.3566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "# Load pre-trained word vectors model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Calculate semantic similarity\n",
        "def calculate_semantic_similarity(sentence1, sentence2):\n",
        "    doc1 = nlp(sentence1)\n",
        "    doc2 = nlp(sentence2)\n",
        "    similarity_score = doc1.similarity(doc2)\n",
        "    return similarity_score\n",
        "\n",
        "gen = \"OLIVER Charles, I thank thee for thy love to me, And in this most unbashful of a passion, Wearing thy hearer in thy mistress’ praise, Thou seem’st so empty and unregarded That thou shouldst have better pleased me with this deed. So holy and so perfect is my love to thee, And I to thee I’ll show it. Now I will forget the pageant and\"\n",
        "exp = \"Oliver appreciates Charles' care and promises to repay him. He knew about his brother's plan and tried to discourage him secretly, but Orlando is determined. Oliver describes Orlando as a determined young man from France, ambitious and envious of others' talents. He's skilled at scheming against Oliver, his own brother. Oliver advises Charles to be cautious.\"\n",
        "\n",
        "# Calculate and print semantic similarity\n",
        "similarity = calculate_semantic_similarity(gen,exp)\n",
        "print(f\"Semantic Similarity: {similarity:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3StQzRm330Xt",
        "outputId": "85ba149e-3e0e-4796-e221-3b78ed0311a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semantic Similarity: 0.6808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-60-ca79c677d323>:9: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity_score = doc1.similarity(doc2)\n"
          ]
        }
      ]
    }
  ]
}